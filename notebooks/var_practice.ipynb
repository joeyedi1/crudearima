{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR (Vector Autoregression) Model - Complete Educational Notebook\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This notebook takes you from **univariate** (ARIMA) to **multivariate** (VAR) time series modeling.\n",
    "\n",
    "By the end, you'll understand:\n",
    "1. Why multiple variables can improve forecasts\n",
    "2. How VAR captures cross-variable dynamics\n",
    "3. Granger causality ‚Äî what it means (and doesn't mean)\n",
    "4. Impulse Response Functions ‚Äî tracing shock effects\n",
    "5. Forecast Error Variance Decomposition ‚Äî understanding forecast uncertainty\n",
    "6. Complete Python implementation\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We'll model **crude oil prices** together with related variables:\n",
    "- **WTI Crude Oil (CL=F)** ‚Äî our main variable of interest\n",
    "- **USD Index (DX-Y.NYB)** ‚Äî oil is priced in dollars\n",
    "- **S&P 500 (^GSPC)** ‚Äî proxy for economic activity / risk sentiment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Conceptual Foundation\n",
    "\n",
    "Before coding, let's understand **why** VAR exists.\n",
    "\n",
    "---\n",
    "\n",
    "## The Limitation of ARIMA\n",
    "\n",
    "ARIMA models oil using **only oil's own history**:\n",
    "\n",
    "```\n",
    "Oil_t = f(Oil_{t-1}, Oil_{t-2}, ...) + noise\n",
    "```\n",
    "\n",
    "But oil prices don't exist in isolation. They're influenced by:\n",
    "- USD strength (oil is priced in dollars)\n",
    "- Stock market (economic activity indicator)\n",
    "- Interest rates, geopolitics, inventory levels...\n",
    "\n",
    "**ARIMA ignores all of this information.**\n",
    "\n",
    "---\n",
    "\n",
    "## VAR: Multiple Variables Together\n",
    "\n",
    "VAR models **all variables simultaneously**, capturing how they influence each other:\n",
    "\n",
    "```\n",
    "Oil_t = c‚ÇÅ + œÜ‚ÇÅ‚ÇÅ¬∑Oil_{t-1} + œÜ‚ÇÅ‚ÇÇ¬∑USD_{t-1} + œÜ‚ÇÅ‚ÇÉ¬∑SP500_{t-1} + Œµ‚ÇÅ_t\n",
    "USD_t = c‚ÇÇ + œÜ‚ÇÇ‚ÇÅ¬∑Oil_{t-1} + œÜ‚ÇÇ‚ÇÇ¬∑USD_{t-1} + œÜ‚ÇÇ‚ÇÉ¬∑SP500_{t-1} + Œµ‚ÇÇ_t  \n",
    "SP500_t = c‚ÇÉ + œÜ‚ÇÉ‚ÇÅ¬∑Oil_{t-1} + œÜ‚ÇÉ‚ÇÇ¬∑USD_{t-1} + œÜ‚ÇÉ‚ÇÉ¬∑SP500_{t-1} + Œµ‚ÇÉ_t\n",
    "```\n",
    "\n",
    "Each variable depends on:\n",
    "- **Its own past** (like AR in ARIMA)\n",
    "- **The past of all other variables** (cross-effects ‚Äî new in VAR!)\n",
    "\n",
    "---\n",
    "\n",
    "## Key VAR Coefficients\n",
    "\n",
    "| Coefficient | What it captures |\n",
    "|-------------|------------------|\n",
    "| œÜ‚ÇÅ‚ÇÅ (Oil ‚Üí Oil) | Oil's own momentum |\n",
    "| œÜ‚ÇÅ‚ÇÇ (USD ‚Üí Oil) | How USD affects oil |\n",
    "| œÜ‚ÇÇ‚ÇÅ (Oil ‚Üí USD) | How oil affects USD |\n",
    "| œÜ‚ÇÇ‚ÇÇ (USD ‚Üí USD) | USD's own momentum |\n",
    "\n",
    "**The cross-effects (œÜ‚ÇÅ‚ÇÇ, œÜ‚ÇÇ‚ÇÅ) are what make VAR powerful!**\n",
    "\n",
    "---\n",
    "\n",
    "## The Curse of Dimensionality\n",
    "\n",
    "VAR(p) with K variables has **K¬≤ √ó p** AR coefficients.\n",
    "\n",
    "| Variables (K) | Lags (p) | Coefficients |\n",
    "|---------------|----------|-------------|\n",
    "| 2 | 1 | 4 |\n",
    "| 3 | 2 | 18 |\n",
    "| 4 | 3 | 48 |\n",
    "| 5 | 4 | 100 |\n",
    "\n",
    "**Rule of thumb:** Need 10-20 observations per parameter.\n",
    "\n",
    "With 500 observations, maximum reasonable: ~4 variables with 2-3 lags.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install yfinance statsmodels pandas numpy matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for our three variables\n",
    "# Using 5 years of daily data for robust estimation\n",
    "\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "print(\"Downloading data...\")\n",
    "\n",
    "# Crude Oil Futures\n",
    "oil = yf.download('CL=F', start=start_date, end=end_date, progress=False)['Close']\n",
    "\n",
    "# USD Index\n",
    "usd = yf.download('DX-Y.NYB', start=start_date, end=end_date, progress=False)['Close']\n",
    "\n",
    "# S&P 500\n",
    "sp500 = yf.download('^GSPC', start=start_date, end=end_date, progress=False)['Close']\n",
    "\n",
    "print(f\"Oil data points: {len(oil)}\")\n",
    "print(f\"USD data points: {len(usd)}\")\n",
    "print(f\"S&P500 data points: {len(sp500)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into single DataFrame\n",
    "# IMPORTANT: Use inner join to keep only dates where ALL variables have data\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Oil': oil,\n",
    "    'USD': usd,\n",
    "    'SP500': sp500\n",
    "})\n",
    "\n",
    "# Drop any rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "print(f\"\\nCombined dataset: {len(data)} observations\")\n",
    "print(f\"Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Data Alignment\n",
    "\n",
    "VAR requires all variables to have the **same dates**. The `dropna()` ensures:\n",
    "- No missing values in any variable\n",
    "- All three series are perfectly aligned\n",
    "\n",
    "If you have missing data, options include:\n",
    "- Forward fill: `data.ffill()` (carry previous value)\n",
    "- Interpolation: `data.interpolate()`\n",
    "- Drop: `data.dropna()` (what we did ‚Äî safest)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all three variables\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "axes[0].plot(data.index, data['Oil'], color='green')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title('WTI Crude Oil')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(data.index, data['USD'], color='blue')\n",
    "axes[1].set_ylabel('Index')\n",
    "axes[1].set_title('USD Index (DXY)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(data.index, data['SP500'], color='red')\n",
    "axes[2].set_ylabel('Index')\n",
    "axes[2].set_title('S&P 500')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 2.1\n",
    "\n",
    "Looking at the plots above:\n",
    "\n",
    "1. Do you see any obvious visual relationship between oil and USD?\n",
    "2. What happened around early 2020? (hint: COVID)\n",
    "3. Do these series look stationary?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations between variables\n",
    "\n",
    "print(\"Correlation Matrix (Levels):\")\n",
    "print(data.corr().round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_matrix = data.corr()\n",
    "plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.xticks(range(3), data.columns)\n",
    "plt.yticks(range(3), data.columns)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Add correlation values as text\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}', \n",
    "                 ha='center', va='center', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Interpreting Correlations\n",
    "\n",
    "| Correlation | Interpretation |\n",
    "|-------------|----------------|\n",
    "| Oil-USD (negative?) | When USD strengthens, oil tends to fall (oil cheaper for non-USD buyers) |\n",
    "| Oil-SP500 (positive?) | Both rise with economic optimism (risk-on) |\n",
    "| USD-SP500 | Varies ‚Äî can be complex relationship |\n",
    "\n",
    "**Warning:** These are **contemporaneous correlations** (same-day). VAR captures **lagged relationships** (yesterday's USD ‚Üí today's oil).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Stationarity Testing\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Critical Requirement\n",
    "\n",
    "**VAR requires ALL variables to be stationary.**\n",
    "\n",
    "If even one variable is non-stationary:\n",
    "- Parameter estimates are unreliable\n",
    "- Standard errors are wrong\n",
    "- Hypothesis tests invalid\n",
    "- Forecasts may explode\n",
    "\n",
    "We must test EACH variable separately.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, name):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test for stationarity.\n",
    "    \n",
    "    H0: Unit root exists (non-stationary)\n",
    "    H1: No unit root (stationary)\n",
    "    \n",
    "    If p-value < 0.05: Reject H0 ‚Üí Stationary\n",
    "    If p-value > 0.05: Fail to reject H0 ‚Üí Non-stationary\n",
    "    \"\"\"\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ADF Test for: {name}\")\n",
    "    print('='*50)\n",
    "    print(f\"ADF Statistic: {result[0]:.4f}\")\n",
    "    print(f\"p-value: {result[1]:.4f}\")\n",
    "    print(f\"Lags Used: {result[2]}\")\n",
    "    print(f\"Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"\\n‚úì STATIONARY (p={result[1]:.4f} < 0.05)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\n‚úó NON-STATIONARY (p={result[1]:.4f} > 0.05)\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each variable\n",
    "print(\"TESTING RAW (LEVEL) DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results_level = {}\n",
    "for col in data.columns:\n",
    "    results_level[col] = adf_test(data[col], col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 3.1\n",
    "\n",
    "Based on the ADF tests above:\n",
    "\n",
    "1. Which variables are stationary?\n",
    "2. Which variables are non-stationary?\n",
    "3. What must we do before fitting VAR?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Differencing to Achieve Stationarity\n",
    "\n",
    "For non-stationary variables, we apply **first differencing**:\n",
    "\n",
    "```\n",
    "ŒîY_t = Y_t - Y_{t-1}\n",
    "```\n",
    "\n",
    "This transforms:\n",
    "- Prices ‚Üí Price **changes** (dollar change)\n",
    "- Alternatively: Log returns ‚Üí **Percentage changes**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply first differencing to ALL variables\n",
    "# Even if some appear stationary, it's common to difference all for consistency\n",
    "\n",
    "# TODO: Fill in the differencing\n",
    "# Hint: Use .diff() method\n",
    "\n",
    "data_diff = pd.DataFrame({\n",
    "    'Oil': data['Oil'].___(),\n",
    "    'USD': data['USD'].___(),\n",
    "    'SP500': data['SP500'].___(),\n",
    "})\n",
    "\n",
    "# Drop the first row (NaN from differencing)\n",
    "data_diff = data_diff.dropna()\n",
    "\n",
    "print(f\"Differenced data: {len(data_diff)} observations\")\n",
    "data_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test stationarity of differenced data\n",
    "print(\"\\nTESTING DIFFERENCED DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results_diff = {}\n",
    "for col in data_diff.columns:\n",
    "    results_diff[col] = adf_test(data_diff[col], f\"{col} (differenced)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize differenced data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "axes[0].plot(data_diff.index, data_diff['Oil'], color='green')\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].set_ylabel('Change ($)')\n",
    "axes[0].set_title('Oil Price Changes (Differenced)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(data_diff.index, data_diff['USD'], color='blue')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_ylabel('Change')\n",
    "axes[1].set_title('USD Index Changes (Differenced)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(data_diff.index, data_diff['SP500'], color='red')\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_ylabel('Change')\n",
    "axes[2].set_title('S&P 500 Changes (Differenced)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: What Differencing Changes\n",
    "\n",
    "**Before (Levels):**\n",
    "- Oil: $70, $72, $71, $75...\n",
    "- Interpretation: Actual price\n",
    "\n",
    "**After (Differences):**\n",
    "- Oil: +$2, -$1, +$4...\n",
    "- Interpretation: Daily change in dollars\n",
    "\n",
    "**Important:** After VAR, your forecasts will be **changes**, not levels. You'll need to cumsum back to get price levels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Lag Order Selection\n",
    "\n",
    "---\n",
    "\n",
    "## How Many Lags (p) Should VAR Have?\n",
    "\n",
    "VAR(p) includes lags 1, 2, ..., p for each variable.\n",
    "\n",
    "**Trade-off:**\n",
    "- Too few lags ‚Üí Miss important dynamics\n",
    "- Too many lags ‚Üí Overfitting, unstable estimates\n",
    "\n",
    "**Solution:** Use Information Criteria (AIC, BIC, HQIC)\n",
    "\n",
    "| Criterion | Penalizes complexity | Tends to select |\n",
    "|-----------|---------------------|----------------|\n",
    "| AIC | Lightly | More lags (better for forecasting) |\n",
    "| BIC | Heavily | Fewer lags (more parsimonious) |\n",
    "| HQIC | Medium | Compromise |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Create VAR model object\n",
    "var_model = VAR(data_diff)\n",
    "\n",
    "# Select optimal lag order\n",
    "# Test lags from 1 to 15\n",
    "max_lags = 15\n",
    "\n",
    "print(\"Selecting Optimal Lag Order\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lag_order_results = var_model.select_order(maxlags=max_lags)\n",
    "print(lag_order_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract recommended lags from each criterion\n",
    "print(\"\\nRecommended Lag Orders:\")\n",
    "print(f\"  AIC: {lag_order_results.aic}\")\n",
    "print(f\"  BIC: {lag_order_results.bic}\")\n",
    "print(f\"  HQIC: {lag_order_results.hqic}\")\n",
    "print(f\"  FPE: {lag_order_results.fpe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 4.1\n",
    "\n",
    "Based on the lag selection results:\n",
    "\n",
    "1. What lag does AIC recommend?\n",
    "2. What lag does BIC recommend?\n",
    "3. Which would you choose for forecasting and why?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select your lag order based on the results above\n",
    "# Common choice: Use BIC for parsimony, or AIC for forecasting\n",
    "\n",
    "optimal_lag = ___  # Fill in your chosen lag\n",
    "\n",
    "print(f\"Selected lag order: p = {optimal_lag}\")\n",
    "print(f\"This means each equation will include lags 1 through {optimal_lag}\")\n",
    "print(f\"Total AR coefficients: {3**2 * optimal_lag} = {3}¬≤ √ó {optimal_lag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Fitting the VAR Model\n",
    "\n",
    "---\n",
    "\n",
    "## What Happens When We Fit VAR?\n",
    "\n",
    "VAR is estimated using **OLS (Ordinary Least Squares)** on each equation separately.\n",
    "\n",
    "For VAR(2) with Oil, USD, SP500:\n",
    "\n",
    "```\n",
    "Oil_t = c‚ÇÅ + œÜ‚ÇÅ‚ÇÅ¬π¬∑Oil_{t-1} + œÜ‚ÇÅ‚ÇÇ¬π¬∑USD_{t-1} + œÜ‚ÇÅ‚ÇÉ¬π¬∑SP500_{t-1}\n",
    "           + œÜ‚ÇÅ‚ÇÅ¬≤¬∑Oil_{t-2} + œÜ‚ÇÅ‚ÇÇ¬≤¬∑USD_{t-2} + œÜ‚ÇÅ‚ÇÉ¬≤¬∑SP500_{t-2} + Œµ‚ÇÅ_t\n",
    "           \n",
    "(similar equations for USD_t and SP500_t)\n",
    "```\n",
    "\n",
    "The superscript indicates the lag number.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the VAR model with selected lag\n",
    "var_results = var_model.fit(optimal_lag)\n",
    "\n",
    "# Print full summary\n",
    "print(var_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Reading the VAR Summary\n",
    "\n",
    "The summary shows **three separate equations** (one for each variable).\n",
    "\n",
    "For each equation, look at:\n",
    "\n",
    "| Column | Meaning |\n",
    "|--------|--------|\n",
    "| **coef** | Estimated coefficient value |\n",
    "| **std err** | Standard error of estimate |\n",
    "| **t** | t-statistic (coef / std err) |\n",
    "| **P>|t|** | p-value ‚Äî is this coefficient significant? |\n",
    "\n",
    "**Key things to check:**\n",
    "1. Which cross-variable effects are significant (p < 0.05)?\n",
    "2. What's the sign of significant coefficients?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 5.1\n",
    "\n",
    "Look at the VAR summary above. Find the coefficient for **L1.USD** in the **Oil equation**.\n",
    "\n",
    "1. What is the coefficient value?\n",
    "2. Is it statistically significant (p < 0.05)?\n",
    "3. What does the sign tell you about the USD ‚Üí Oil relationship?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model stability\n",
    "# All eigenvalues of the companion matrix must be inside the unit circle\n",
    "\n",
    "print(\"\\nModel Stability Check\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "is_stable = var_results.is_stable()\n",
    "print(f\"Is model stable? {is_stable}\")\n",
    "\n",
    "if is_stable:\n",
    "    print(\"‚úì All roots inside unit circle ‚Äî model is stable\")\n",
    "else:\n",
    "    print(\"‚úó WARNING: Model is unstable ‚Äî forecasts may explode!\")\n",
    "    print(\"  Consider: more differencing, fewer lags, or removing variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the roots\n",
    "# Stable if all roots are inside the unit circle (radius < 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot unit circle\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax.plot(np.cos(theta), np.sin(theta), 'b-', label='Unit Circle')\n",
    "\n",
    "# Plot roots\n",
    "roots = var_results.roots\n",
    "ax.scatter(roots.real, roots.imag, marker='x', s=100, c='red', label='VAR Roots')\n",
    "\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax.set_xlabel('Real')\n",
    "ax.set_ylabel('Imaginary')\n",
    "ax.set_title('VAR Stability: Roots Should Be Inside Unit Circle')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Stability and Roots\n",
    "\n",
    "**Why stability matters:**\n",
    "- Stable VAR: Shocks fade over time ‚Üí sensible forecasts\n",
    "- Unstable VAR: Shocks grow over time ‚Üí exploding forecasts\n",
    "\n",
    "**The root plot:**\n",
    "- All red X's should be **inside** the blue circle\n",
    "- If any are on or outside ‚Üí unstable model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: VAR Diagnostics\n",
    "\n",
    "---\n",
    "\n",
    "## Diagnostic Tests for VAR\n",
    "\n",
    "Just like ARIMA, we need to verify our model is well-specified.\n",
    "\n",
    "| Test | What it checks | Pass condition |\n",
    "|------|---------------|----------------|\n",
    "| Residual autocorrelation | No leftover patterns | p > 0.05 |\n",
    "| Normality | Errors approximately normal | p > 0.05 (often fails for finance) |\n",
    "| Stability | Roots inside unit circle | is_stable() = True |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for residual autocorrelation (Portmanteau test)\n",
    "# This is the multivariate version of Ljung-Box\n",
    "\n",
    "print(\"Residual Autocorrelation Test (Portmanteau/Ljung-Box)\")\n",
    "print(\"=\"*60)\n",
    "print(\"H0: No residual autocorrelation\")\n",
    "print(\"H1: Residual autocorrelation exists\")\n",
    "print()\n",
    "\n",
    "whiteness_test = var_results.test_whiteness(nlags=10, signif=0.05)\n",
    "print(f\"Test statistic: {whiteness_test.test_statistic:.4f}\")\n",
    "print(f\"p-value: {whiteness_test.pvalue:.4f}\")\n",
    "\n",
    "if whiteness_test.pvalue > 0.05:\n",
    "    print(\"\\n‚úì Residuals are white noise (no autocorrelation)\")\n",
    "else:\n",
    "    print(\"\\n‚úó Residuals have autocorrelation ‚Äî consider more lags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normality of residuals\n",
    "print(\"\\nResidual Normality Test (Jarque-Bera)\")\n",
    "print(\"=\"*60)\n",
    "print(\"H0: Residuals are normally distributed\")\n",
    "print(\"H1: Residuals are not normal\")\n",
    "print()\n",
    "\n",
    "normality_test = var_results.test_normality()\n",
    "print(normality_test.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Normality in Financial Data\n",
    "\n",
    "**Normality tests often fail for financial data.** This is expected because:\n",
    "- Fat tails (extreme moves more common than normal predicts)\n",
    "- Volatility clustering (calm periods ‚Üí volatile periods)\n",
    "- Skewness (crashes are larger than rallies)\n",
    "\n",
    "**What to do:**\n",
    "- Mild non-normality: Acceptable for point forecasts\n",
    "- Severe non-normality: Consider robust standard errors, bootstrap confidence intervals\n",
    "\n",
    "**Don't reject a model just because normality fails.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals for each equation\n",
    "residuals = var_results.resid\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "\n",
    "for i, col in enumerate(residuals.columns):\n",
    "    # Time series plot\n",
    "    axes[i, 0].plot(residuals.index, residuals[col])\n",
    "    axes[i, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[i, 0].set_title(f'{col} Residuals Over Time')\n",
    "    axes[i, 0].set_ylabel('Residual')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram\n",
    "    axes[i, 1].hist(residuals[col], bins=50, density=True, alpha=0.7)\n",
    "    axes[i, 1].set_title(f'{col} Residual Distribution')\n",
    "    axes[i, 1].set_xlabel('Residual')\n",
    "    axes[i, 1].set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 6.1\n",
    "\n",
    "Looking at the diagnostic results:\n",
    "\n",
    "1. Does the whiteness test pass (no residual autocorrelation)?\n",
    "2. Do the residual time series plots look random (no patterns)?\n",
    "3. Do the histograms look approximately normal?\n",
    "4. Overall, is this model acceptable?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Granger Causality\n",
    "\n",
    "---\n",
    "\n",
    "## What is Granger Causality?\n",
    "\n",
    "**Definition:** X \"Granger-causes\" Y if past values of X help predict Y, **beyond what Y's own past provides**.\n",
    "\n",
    "**Key warning:** This is **predictive causality**, NOT true causality!\n",
    "\n",
    "| Finding | Correct interpretation | WRONG interpretation |\n",
    "|---------|----------------------|---------------------|\n",
    "| USD Granger-causes Oil | Past USD helps predict oil | USD causes oil to move |\n",
    "\n",
    "---\n",
    "\n",
    "## The Test\n",
    "\n",
    "Compare two models:\n",
    "- **Restricted:** Oil_t = f(Oil_{t-1}, Oil_{t-2}, ...)\n",
    "- **Unrestricted:** Oil_t = f(Oil_{t-1}, Oil_{t-2}, ..., USD_{t-1}, USD_{t-2}, ...)\n",
    "\n",
    "If unrestricted is **significantly better** ‚Üí USD Granger-causes Oil\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "def granger_test(data, cause, effect, max_lag):\n",
    "    \"\"\"\n",
    "    Test if 'cause' Granger-causes 'effect'.\n",
    "    \n",
    "    H0: cause does NOT Granger-cause effect\n",
    "    H1: cause DOES Granger-cause effect\n",
    "    \n",
    "    p < 0.05: Reject H0 ‚Üí Granger causality exists\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing: Does {cause} Granger-cause {effect}?\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # grangercausalitytests expects [effect, cause] order\n",
    "    test_data = data[[effect, cause]]\n",
    "    \n",
    "    # Run tests for multiple lags\n",
    "    results = grangercausalitytests(test_data, maxlag=max_lag, verbose=False)\n",
    "    \n",
    "    # Extract p-values from F-test\n",
    "    print(f\"\\n{'Lag':<6} {'F-statistic':<15} {'p-value':<12} {'Significant?'}\")\n",
    "    print('-'*50)\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        f_stat = results[lag][0]['ssr_ftest'][0]\n",
    "        p_val = results[lag][0]['ssr_ftest'][1]\n",
    "        sig = \"Yes ***\" if p_val < 0.01 else \"Yes **\" if p_val < 0.05 else \"Yes *\" if p_val < 0.10 else \"No\"\n",
    "        print(f\"{lag:<6} {f_stat:<15.4f} {p_val:<12.4f} {sig}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all pairwise Granger causality relationships\n",
    "max_test_lag = 4\n",
    "\n",
    "# Does USD Granger-cause Oil?\n",
    "results_usd_oil = granger_test(data_diff, 'USD', 'Oil', max_test_lag)\n",
    "\n",
    "# Does Oil Granger-cause USD?\n",
    "results_oil_usd = granger_test(data_diff, 'Oil', 'USD', max_test_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does SP500 Granger-cause Oil?\n",
    "results_sp_oil = granger_test(data_diff, 'SP500', 'Oil', max_test_lag)\n",
    "\n",
    "# Does Oil Granger-cause SP500?\n",
    "results_oil_sp = granger_test(data_diff, 'Oil', 'SP500', max_test_lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 7.1\n",
    "\n",
    "Based on the Granger causality tests above:\n",
    "\n",
    "1. Does USD Granger-cause Oil? (at 5% significance)\n",
    "2. Does Oil Granger-cause USD?\n",
    "3. Does SP500 Granger-cause Oil?\n",
    "4. What does this tell you about which variables are useful for forecasting oil?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of Granger causality results\n",
    "# Using lag 2 as representative (you can adjust)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRANGER CAUSALITY SUMMARY (Lag 2)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Cause':<10} ‚Üí {'Effect':<10} {'p-value':<12} {'Conclusion'}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "pairs = [\n",
    "    ('USD', 'Oil', results_usd_oil),\n",
    "    ('Oil', 'USD', results_oil_usd),\n",
    "    ('SP500', 'Oil', results_sp_oil),\n",
    "    ('Oil', 'SP500', results_oil_sp),\n",
    "]\n",
    "\n",
    "for cause, effect, result in pairs:\n",
    "    p_val = result[2][0]['ssr_ftest'][1]\n",
    "    conclusion = \"Granger-causes\" if p_val < 0.05 else \"No causality\"\n",
    "    print(f\"{cause:<10} ‚Üí {effect:<10} {p_val:<12.4f} {conclusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Impulse Response Functions (IRF)\n",
    "\n",
    "---\n",
    "\n",
    "## What is an Impulse Response Function?\n",
    "\n",
    "IRF answers: **\"If one variable gets shocked today, how do ALL variables respond over time?\"**\n",
    "\n",
    "**Example question:** If oil price suddenly jumps by $1 today (unexpected shock), what happens to:\n",
    "- Oil over the next 20 days?\n",
    "- USD over the next 20 days?\n",
    "- SP500 over the next 20 days?\n",
    "\n",
    "IRF traces out these **dynamic responses**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why IRF Matters\n",
    "\n",
    "| Use case | What IRF tells you |\n",
    "|----------|--------------------|\n",
    "| Policy analysis | How do markets respond to interventions? |\n",
    "| Risk management | If oil spikes, what happens to my USD position? |\n",
    "| Understanding dynamics | How fast do shocks transmit between markets? |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Impulse Response Functions\n",
    "# periods = how many time steps to trace\n",
    "\n",
    "irf = var_results.irf(periods=20)\n",
    "\n",
    "# Plot all IRFs\n",
    "fig = irf.plot(figsize=(14, 10))\n",
    "plt.suptitle('Impulse Response Functions', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Reading IRF Plots\n",
    "\n",
    "The IRF plot is a **3√ó3 grid** (for 3 variables):\n",
    "\n",
    "| Row | Column | Shows |\n",
    "|-----|--------|-------|\n",
    "| Oil | Oil | Response of Oil to Oil shock |\n",
    "| Oil | USD | Response of Oil to USD shock |\n",
    "| USD | Oil | Response of USD to Oil shock |\n",
    "| etc. | etc. | etc. |\n",
    "\n",
    "**What to look for:**\n",
    "- **Direction:** Does response go positive or negative?\n",
    "- **Timing:** When is peak response? Immediate or delayed?\n",
    "- **Persistence:** How quickly does effect fade to zero?\n",
    "- **Confidence bands:** Is the response statistically significant?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on specific responses of interest\n",
    "# Response of OIL to shocks from each variable\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# IRF values: irf.irfs[period, response_variable, shock_variable]\n",
    "periods = range(21)\n",
    "\n",
    "# Response of Oil to Oil shock\n",
    "axes[0].plot(periods, irf.irfs[:, 0, 0], 'b-', linewidth=2)\n",
    "axes[0].fill_between(periods, irf.irfs[:, 0, 0] - 1.96*irf.stderr()[:, 0, 0],\n",
    "                     irf.irfs[:, 0, 0] + 1.96*irf.stderr()[:, 0, 0], alpha=0.3)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0].set_title('Oil Response to OIL Shock')\n",
    "axes[0].set_xlabel('Days')\n",
    "axes[0].set_ylabel('Response')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Response of Oil to USD shock\n",
    "axes[1].plot(periods, irf.irfs[:, 0, 1], 'b-', linewidth=2)\n",
    "axes[1].fill_between(periods, irf.irfs[:, 0, 1] - 1.96*irf.stderr()[:, 0, 1],\n",
    "                     irf.irfs[:, 0, 1] + 1.96*irf.stderr()[:, 0, 1], alpha=0.3)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('Oil Response to USD Shock')\n",
    "axes[1].set_xlabel('Days')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Response of Oil to SP500 shock\n",
    "axes[2].plot(periods, irf.irfs[:, 0, 2], 'b-', linewidth=2)\n",
    "axes[2].fill_between(periods, irf.irfs[:, 0, 2] - 1.96*irf.stderr()[:, 0, 2],\n",
    "                     irf.irfs[:, 0, 2] + 1.96*irf.stderr()[:, 0, 2], alpha=0.3)\n",
    "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[2].set_title('Oil Response to SP500 Shock')\n",
    "axes[2].set_xlabel('Days')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 8.1\n",
    "\n",
    "Looking at the IRF plots for Oil:\n",
    "\n",
    "1. How does Oil respond to its own shock? (immediate? fades quickly?)\n",
    "2. How does Oil respond to a USD shock? (positive/negative? delayed?)\n",
    "3. How does Oil respond to an SP500 shock?\n",
    "4. Which shocks have the most persistent effect on Oil?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9: Forecast Error Variance Decomposition (FEVD)\n",
    "\n",
    "---\n",
    "\n",
    "## What is FEVD?\n",
    "\n",
    "FEVD answers: **\"Of all the uncertainty in my forecast, how much comes from each variable?\"**\n",
    "\n",
    "**Example output:**\n",
    "```\n",
    "Oil forecast variance at horizon 10:\n",
    "- Oil shocks: 80%\n",
    "- USD shocks: 15%\n",
    "- SP500 shocks: 5%\n",
    "```\n",
    "\n",
    "**Interpretation:** 80% of oil's unpredictability comes from oil-specific factors. USD explains 15% of the forecast uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Misunderstanding\n",
    "\n",
    "FEVD is **NOT** about forecast accuracy!\n",
    "\n",
    "| FEVD says | Does NOT mean |\n",
    "|-----------|---------------|\n",
    "| \"80% from oil shocks\" | \"80% chance of being wrong\" |\n",
    "| | It means: \"Of the forecast error, 80% is due to oil-specific surprises\" |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Forecast Error Variance Decomposition\n",
    "fevd = var_results.fevd(periods=20)\n",
    "\n",
    "# Print summary\n",
    "print(fevd.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FEVD\n",
    "fig = fevd.plot(figsize=(14, 8))\n",
    "plt.suptitle('Forecast Error Variance Decomposition', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FEVD for Oil specifically\n",
    "print(\"\\nFEVD for OIL Forecast:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\n{'Horizon':<10} {'Oil %':<12} {'USD %':<12} {'SP500 %':<12}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# FEVD is stored as fevd.decomp[horizon, variable, shock_source]\n",
    "for h in [1, 5, 10, 15, 20]:\n",
    "    oil_pct = fevd.decomp[h-1, 0, 0] * 100\n",
    "    usd_pct = fevd.decomp[h-1, 0, 1] * 100\n",
    "    sp_pct = fevd.decomp[h-1, 0, 2] * 100\n",
    "    print(f\"{h:<10} {oil_pct:<12.1f} {usd_pct:<12.1f} {sp_pct:<12.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 9.1\n",
    "\n",
    "Looking at the FEVD results for Oil:\n",
    "\n",
    "1. At horizon 1 (tomorrow), what % of oil's forecast variance is due to oil's own shocks?\n",
    "2. At horizon 20, does USD become more or less important?\n",
    "3. What does this tell you about the speed of shock transmission?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 10: Forecasting\n",
    "\n",
    "---\n",
    "\n",
    "## VAR Forecasting Process\n",
    "\n",
    "1. VAR predicts **all variables simultaneously**\n",
    "2. Since we differenced, forecasts are **changes**, not levels\n",
    "3. To get price levels, we must **cumsum** and add to last known price\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for out-of-sample testing\n",
    "# Use last 60 days as test set\n",
    "\n",
    "test_size = 60\n",
    "train_diff = data_diff.iloc[:-test_size]\n",
    "test_diff = data_diff.iloc[-test_size:]\n",
    "\n",
    "# Also keep level data for converting forecasts back\n",
    "train_level = data.iloc[:-test_size]\n",
    "test_level = data.iloc[-test_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_diff)} observations\")\n",
    "print(f\"Test set: {len(test_diff)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit VAR on training data only\n",
    "var_train = VAR(train_diff)\n",
    "var_train_fit = var_train.fit(optimal_lag)\n",
    "\n",
    "print(f\"VAR({optimal_lag}) fitted on training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts for test period\n",
    "# We need to provide the last 'p' observations as initial values\n",
    "\n",
    "forecast_horizon = len(test_diff)\n",
    "\n",
    "# Get last p observations from training data\n",
    "lag_order = var_train_fit.k_ar\n",
    "forecast_input = train_diff.values[-lag_order:]\n",
    "\n",
    "# Forecast (returns differenced values)\n",
    "forecast_diff = var_train_fit.forecast(forecast_input, steps=forecast_horizon)\n",
    "\n",
    "# Convert to DataFrame\n",
    "forecast_diff_df = pd.DataFrame(\n",
    "    forecast_diff,\n",
    "    index=test_diff.index,\n",
    "    columns=['Oil', 'USD', 'SP500']\n",
    ")\n",
    "\n",
    "print(\"Forecasts (differenced):\")\n",
    "forecast_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert differenced forecasts back to levels\n",
    "# Formula: Level_t = Level_{t-1} + Diff_t\n",
    "# Equivalent to: cumsum starting from last known level\n",
    "\n",
    "# Last known levels (from training data)\n",
    "last_levels = train_level.iloc[-1]\n",
    "print(\"Last known prices:\")\n",
    "print(last_levels)\n",
    "\n",
    "# Convert to levels by cumsum + last level\n",
    "forecast_level_df = forecast_diff_df.cumsum() + last_levels\n",
    "\n",
    "print(\"\\nForecasts (levels):\")\n",
    "forecast_level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts vs actuals for Oil\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot training data (last 100 days)\n",
    "plot_start = -100 - test_size\n",
    "plt.plot(train_level['Oil'].iloc[plot_start:].index, \n",
    "         train_level['Oil'].iloc[plot_start:], \n",
    "         label='Training Data', color='blue')\n",
    "\n",
    "# Plot actual test data\n",
    "plt.plot(test_level['Oil'].index, test_level['Oil'], \n",
    "         label='Actual', color='green', linewidth=2)\n",
    "\n",
    "# Plot forecast\n",
    "plt.plot(forecast_level_df['Oil'].index, forecast_level_df['Oil'], \n",
    "         label='VAR Forecast', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.axvline(x=train_level.index[-1], color='black', linestyle=':', alpha=0.7)\n",
    "plt.title('VAR Oil Price Forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Oil Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Note: Multi-Step Forecast Limitations\n",
    "\n",
    "Like ARIMA, VAR multi-step forecasts have limitations:\n",
    "\n",
    "1. **Errors compound:** Each step's forecast becomes input for the next\n",
    "2. **Converges to unconditional mean:** Long-horizon forecasts flatten out\n",
    "3. **No new information:** Can't anticipate future shocks\n",
    "\n",
    "**Better approach:** Rolling forecast (re-estimate with each new observation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 11: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_forecast(actual, predicted, name):\n",
    "    \"\"\"Calculate and print forecast evaluation metrics.\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    \n",
    "    print(f\"\\n{name} Forecast Evaluation:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return rmse, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VAR forecast for each variable\n",
    "print(\"=\"*50)\n",
    "print(\"VAR MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "var_metrics = {}\n",
    "for col in ['Oil', 'USD', 'SP500']:\n",
    "    metrics = evaluate_forecast(test_level[col], forecast_level_df[col], col)\n",
    "    var_metrics[col] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 12: Comparison with Univariate ARIMA\n",
    "\n",
    "---\n",
    "\n",
    "## The Key Question\n",
    "\n",
    "**Does VAR (multivariate) actually beat ARIMA (univariate)?**\n",
    "\n",
    "Let's find out by fitting ARIMA to oil alone and comparing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit ARIMA on oil training data (differenced implicitly via d=1)\n",
    "arima_model = ARIMA(train_level['Oil'], order=(2, 1, 2))\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "# Forecast\n",
    "arima_forecast = arima_fit.forecast(steps=forecast_horizon)\n",
    "arima_forecast.index = test_level.index\n",
    "\n",
    "print(\"ARIMA(2,1,2) fitted for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ARIMA\n",
    "print(\"=\"*50)\n",
    "print(\"ARIMA MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "arima_metrics = evaluate_forecast(test_level['Oil'], arima_forecast, 'Oil (ARIMA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare VAR vs ARIMA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON: OIL FORECASTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n{'Model':<20} {'RMSE':<12} {'MAE':<12} {'MAPE':<12}\")\n",
    "print(\"-\"*55)\n",
    "print(f\"{'VAR':<20} {var_metrics['Oil'][0]:<12.4f} {var_metrics['Oil'][1]:<12.4f} {var_metrics['Oil'][2]:<12.2f}%\")\n",
    "print(f\"{'ARIMA':<20} {arima_metrics[0]:<12.4f} {arima_metrics[1]:<12.4f} {arima_metrics[2]:<12.2f}%\")\n",
    "\n",
    "# Which is better?\n",
    "if var_metrics['Oil'][0] < arima_metrics[0]:\n",
    "    improvement = (arima_metrics[0] - var_metrics['Oil'][0]) / arima_metrics[0] * 100\n",
    "    print(f\"\\n‚úì VAR outperforms ARIMA by {improvement:.1f}% (RMSE)\")\n",
    "else:\n",
    "    degradation = (var_metrics['Oil'][0] - arima_metrics[0]) / arima_metrics[0] * 100\n",
    "    print(f\"\\n‚úó ARIMA outperforms VAR by {degradation:.1f}% (RMSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(test_level['Oil'].index, test_level['Oil'], \n",
    "         label='Actual', color='black', linewidth=2)\n",
    "plt.plot(forecast_level_df['Oil'].index, forecast_level_df['Oil'], \n",
    "         label='VAR Forecast', color='blue', linestyle='--', linewidth=2)\n",
    "plt.plot(arima_forecast.index, arima_forecast, \n",
    "         label='ARIMA Forecast', color='red', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.title('VAR vs ARIMA: Oil Price Forecasting Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Oil Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question 12.1\n",
    "\n",
    "Based on the comparison:\n",
    "\n",
    "1. Which model performed better for oil price forecasting?\n",
    "2. Why might the \"simpler\" model sometimes win?\n",
    "3. In what situations might VAR have a bigger advantage over ARIMA?\n",
    "\n",
    "**Your Answers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13: Summary and Key Takeaways\n",
    "\n",
    "---\n",
    "\n",
    "## What You've Learned\n",
    "\n",
    "| Concept | Key insight |\n",
    "|---------|-------------|\n",
    "| **VAR structure** | Each variable depends on lags of ALL variables |\n",
    "| **Stationarity** | ALL variables must be stationary before fitting |\n",
    "| **Lag selection** | Use AIC/BIC; watch for curse of dimensionality |\n",
    "| **Granger causality** | Predictive, NOT true causality |\n",
    "| **IRF** | Traces dynamic response to shocks |\n",
    "| **FEVD** | Decomposes forecast uncertainty by source |\n",
    "| **VAR vs ARIMA** | More variables ‚â† always better |\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use VAR\n",
    "\n",
    "| Use VAR when... | Use ARIMA when... |\n",
    "|-----------------|-------------------|\n",
    "| Variables clearly interact | Single variable sufficient |\n",
    "| Cross-variable dynamics matter | Simplicity preferred |\n",
    "| You need IRF/FEVD analysis | Limited data available |\n",
    "| Granger tests show significant causality | No significant cross-effects |\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations of VAR\n",
    "\n",
    "1. **Curse of dimensionality:** Parameters grow as K¬≤ √ó p\n",
    "2. **All variables treated as endogenous:** May not match economic theory\n",
    "3. **Stationarity required:** Must difference (loses long-run relationships)\n",
    "4. **Linear only:** Can't capture non-linear dynamics\n",
    "5. **No exogenous shocks:** Can't include OPEC announcements, geopolitical events\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Final Assessment\n",
    "\n",
    "Complete this summary:\n",
    "\n",
    "| Question | Your Answer |\n",
    "|----------|-------------|\n",
    "| How many AR coefficients in VAR(3) with 4 variables? | |\n",
    "| What does Granger causality actually test? | |\n",
    "| What does FEVD tell you? | |\n",
    "| When would VAR beat ARIMA? | |\n",
    "| What's the main limitation of VAR? | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Challenges\n",
    "\n",
    "If you want to practice more:\n",
    "\n",
    "1. **Add a 4th variable** (Natural Gas: NG=F) and re-run the analysis\n",
    "2. **Implement rolling VAR forecast** (re-estimate each day)\n",
    "3. **Test for cointegration** using Johansen test ‚Äî if found, try VECM\n",
    "4. **Try log returns** instead of simple differences\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your bonus challenge code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
